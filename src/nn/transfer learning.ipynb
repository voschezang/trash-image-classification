{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "import os\n",
    "import os, sklearn, pandas, numpy as np, random\n",
    "from sklearn import svm\n",
    "import skimage, skimage.io, skimage.filters\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import TensorBoard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Tristan/Downloads/dog-breed-identification/src'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set cwd back to default\n",
    "os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset :: namedtuple(\n",
      "    ['train' = ['img_name']\n",
      "    , 'train_final' = ['img_name']\n",
      "    , 'test' = ['img_name']\n",
      "    , 'test_final' = ['img_name']\n",
      "    , 'labels' = pandas.df('img_name','breed')\n",
      "    , 'dict_index_to_label' = dict to convert label_index -> label_name\n",
      "    , 'dict_label_to_index'= dict to convert label_name -> label_index\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# custom scripts\n",
    "import config # params, constants\n",
    "import data, models # functions that mutate outr data\n",
    "# from utils import utils, plot # custom functions, in local environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data # src/data.py\n",
    "dataset = data.init_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the amount of classes that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scottish_deerhound', 'maltese_dog', 'afghan_hound']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick the n classes with the most occuring instances\n",
    "amt = 3\n",
    "classes = data.top_classes(dataset.labels, amt)\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 256, 256\n",
    "train_data_dir = \"data/train\"\n",
    "validation_data_dir = \"data/val\"\n",
    "# batch_size = 16\n",
    "# epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ??????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = []\n",
    "n_per_class = []\n",
    "tail = '.jpg'\n",
    "for cls in classes:\n",
    "    names = data.items_with_label(dataset.labels, cls)\n",
    "    train_names = [f for f in names if (f + tail) in dataset.train]\n",
    "    name_list.append(train_names)\n",
    "    n_per_class.append(len(train_names))\n",
    "    \n",
    "n = min(n_per_class)\n",
    "# (optional) reduce n to check whether the model can rember its input\n",
    "reduced_n = 50\n",
    "if n > reduced_n:    n = reduced_n\n",
    "x = []\n",
    "for ls in name_list:\n",
    "    for name in ls[:n]:\n",
    "        x.append(name)\n",
    "random.shuffle(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and convert images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('extract all data:', 150)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, n = data.extract_all(dataset, x)\n",
    "y_test = y_train\n",
    "y_train, y_test = data.labels_to_vectors(dataset, y_train, y_test)\n",
    "\n",
    "input_shape = x_train.shape[1:] # = shape of an individual image (matrix)\n",
    "output_length = (y_train[0]).shape[0] # = length of an individual label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate VG16 network and add extra layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model \n",
    "dropout = 0.10\n",
    "\n",
    "# build the VGG16 network\n",
    "model = applications.VGG16(weights='imagenet', include_top=False, input_shape = input_shape )\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "# x = Dense(1024, activation=\"relu\")(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(1024, activation=\"relu\")(x)\n",
    "x = (Dense(128, activation='relu'))(x)\n",
    "x = (Dense(16, activation='relu'))(x)\n",
    "x = (Dropout(dropout))(x)\n",
    "x = (Dense(output_length,activation='softmax'))(x)\n",
    "predictions = Dense(output_length, activation=\"softmax\")(x)\n",
    "\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "learning_rate = 0.001\n",
    "# Adam, SGD\n",
    "# sgd = Keras.optimizers.SGD(lr=0.01, clipnorm=1.)\n",
    "optimizer = optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizer, metrics=['accuracy',\n",
    "    'mean_squared_error','categorical_crossentropy','top_k_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = \"nearest\",\n",
    "    zoom_range = 0.3,\n",
    "    width_shift_range = 0.3,\n",
    "    height_shift_range=0.3,\n",
    "    rotation_range=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# n epochs = n iterations over all the training data\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 92s 10s/step - loss: 4.5580 - acc: 0.2905 - mean_squared_error: 0.0093 - categorical_crossentropy: 4.5580 - top_k_categorical_accuracy: 0.3958\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 104s 12s/step - loss: 4.5021 - acc: 0.3232 - mean_squared_error: 0.0093 - categorical_crossentropy: 4.5021 - top_k_categorical_accuracy: 0.6628\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 98s 11s/step - loss: 4.4715 - acc: 0.2389 - mean_squared_error: 0.0093 - categorical_crossentropy: 4.4715 - top_k_categorical_accuracy: 0.8314\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 96s 11s/step - loss: 4.4366 - acc: 0.3021 - mean_squared_error: 0.0093 - categorical_crossentropy: 4.4366 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 108s 12s/step - loss: 4.4004 - acc: 0.3611 - mean_squared_error: 0.0093 - categorical_crossentropy: 4.4004 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 79s 9s/step - loss: 4.3649 - acc: 0.3717 - mean_squared_error: 0.0093 - categorical_crossentropy: 4.3649 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 127s 14s/step - loss: 4.3333 - acc: 0.3264 - mean_squared_error: 0.0093 - categorical_crossentropy: 4.3333 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 138s 15s/step - loss: 4.3024 - acc: 0.2810 - mean_squared_error: 0.0093 - categorical_crossentropy: 4.3024 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 120s 13s/step - loss: 4.2654 - acc: 0.3748 - mean_squared_error: 0.0093 - categorical_crossentropy: 4.2654 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 133s 15s/step - loss: 4.2325 - acc: 0.3888 - mean_squared_error: 0.0093 - categorical_crossentropy: 4.2325 - top_k_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10fb718d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen.fit(x_train)\n",
    "\n",
    "model_final.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x_train) / batch_size, epochs=epochs, callbacks=[TensorBoard(log_dir=config.tmp_model_dir)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "model_final.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "          validation_split=1/6, callbacks=[TensorBoard(log_dir=config.tmp_model_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
