{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "import os\n",
    "import os, sklearn, pandas, numpy as np, random\n",
    "from sklearn import svm\n",
    "import skimage, skimage.io, skimage.filters\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.utils import shuffle\n",
    "import imp\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# from pcanet import PCANet\n",
    "from pcanet import PCANet\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Tristan/Downloads/dog-breed-identification/src'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set cwd back to default\n",
    "os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset :: namedtuple(\n",
      "    ['train' = ['img_name']\n",
      "    , 'test' = ['img_name']\n",
      "    , 'validation' = ['img_name']\n",
      "    , 'labels' = pandas.df('img_name','label')\n",
      "    , 'dict_index_to_label' = dict to convert label_index -> label_name\n",
      "    , 'dict_label_to_index'= dict to convert label_name -> label_index\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# custom scripts\n",
    "import config # params, constants\n",
    "import data, models # functions that mutate outr data\n",
    "# from utils import utils, plot # custom functions, in local environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data # src/data.py\n",
    "dataset = data.init_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the amount of classes that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paper', 'glass', 'plastic', 'metal', 'cardboard']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick the n classes with the most occuring instances\n",
    "amt = 5\n",
    "classes = data.top_classes(dataset.labels, amt)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper\n",
      "glass\n",
      "plastic\n",
      "metal\n",
      "cardboard\n",
      "paper\n",
      "glass\n",
      "plastic\n",
      "metal\n",
      "cardboard\n",
      "paper\n",
      "glass\n",
      "plastic\n",
      "metal\n",
      "cardboard\n"
     ]
    }
   ],
   "source": [
    "def extract_topx_classes(classes, train_or_test):\n",
    "    name_list = []\n",
    "    n_per_class = []\n",
    "    tail = '.jpg'\n",
    "    for cls in classes:\n",
    "        print(cls)\n",
    "        names = data.items_with_label(dataset.labels, cls)\n",
    "        if train_or_test == 'train':\n",
    "            train_names = [f for f in names if (f) in dataset.train]\n",
    "        if train_or_test == 'test':\n",
    "            train_names = [f for f in names if (f) in dataset.test]\n",
    "        if train_or_test == 'validation':\n",
    "            train_names = [f for f in names if (f) in dataset.validation]\n",
    "        name_list.append(train_names)\n",
    "        n_per_class.append(len(train_names))\n",
    "\n",
    "    n = min(n_per_class)\n",
    "    # (optional) reduce n to check whether the model can rember its input\n",
    "#     reduced_n = 50\n",
    "#     if n > reduced_n:    n = reduced_n\n",
    "    x = []\n",
    "    for ls in name_list:\n",
    "        for name in ls:\n",
    "            x.append(name)\n",
    "    random.shuffle(x)\n",
    "    return x\n",
    "\n",
    "x_train = extract_topx_classes(classes, 'train')\n",
    "x_test = extract_topx_classes(classes, 'test')\n",
    "x_validation = extract_topx_classes(classes, 'validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and convert images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('extract all data:', 1940)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, n = data.extract_all(dataset, x_train)\n",
    "# y_test = y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('extract all data:', 300)\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test, n = data.extract_all_test(dataset, x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('extract all data:', 150)\n"
     ]
    }
   ],
   "source": [
    "x_validation, y_validation, n  = data.extract_all_validation(dataset, x_validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels and determine input and output shape for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train, y_test, y_validation = data.labels_to_vectors(dataset, y_train, y_test, y_validation)\n",
    "y_train = data.one_hot(y_train)\n",
    "y_test = data.one_hot(y_test)\n",
    "y_validation = data.one_hot(y_validation)\n",
    "input_shape = x_train.shape[1:] # = shape of an individual image (matrix)\n",
    "output_length = (y_train[0]).shape[0] # = length of an individual label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x1_train[0:10])\n",
    "print(y_train[0:10])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate VG16 network and add extra layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model \n",
    "\n",
    "def get_model(learn_rate=0.0001, batches=10, dropout=0.10):\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(weights='imagenet', include_top=False, input_shape = input_shape )\n",
    "    print('Model loaded.')\n",
    "\n",
    "    # build a classifier model to put on top of the convolutional model\n",
    "    # top_model = Sequential()\n",
    "    # top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "    # top_model.add(Dense(256, activation='relu'))\n",
    "    # top_model.add(Dropout(0.5))\n",
    "    # top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    for layer in model.layers[:13]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #Adding custom Layers \n",
    "    x = model.output\n",
    "    x = Flatten()(x)\n",
    "    x = (Dropout(dropout))(x)\n",
    "    x = (Dense(2048, activation='relu'))(x) #128\n",
    "    x = (Dense(2048, activation='relu'))(x) #128\n",
    "    x = (Dense(1024, activation='relu'))(x)\n",
    "    # softmax output to get probability distribution\n",
    "    predictions = Dense(output_length, activation=\"softmax\")(x) #activation=\"softmax\"\n",
    "\n",
    "\n",
    "    # creating the final model \n",
    "    model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "    # Adam, SGD\n",
    "    # sgd = Keras.optimizers.SGD(lr=0.01, clipnorm=1.)\n",
    "    optimizer = optimizers.Adam(lr=learn_rate)\n",
    "\n",
    "    # compile the model \n",
    "    model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizer, metrics=['accuracy',\n",
    "        'mean_squared_error','categorical_crossentropy','top_k_categorical_accuracy'])\n",
    "    \n",
    "    return model_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import time\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "batches = [5, 10, 20]\n",
    "learn_rate = [0.0001, 0.001, 0.01]\n",
    "dropout = [0.1, 0.3, 0.5] # most used values\n",
    "param_grid = dict(learn_rate=learn_rate, batch_size=batches, dropout=dropout)\n",
    "\n",
    "# tune the hyperparameters via a randomized search\n",
    "model = KerasClassifier(build_fn=get_model, verbose=0)\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid)\n",
    "start = time.time()\n",
    "grid.fit(x_validation, y_validation)\n",
    " \n",
    "# evaluate the best randomized searched model on the testing\n",
    "# data\n",
    "print(\"[INFO] randomized search took {:.2f} seconds\".format(\n",
    "    time.time() - start))\n",
    "acc = grid.score(x_validation, y_validation)\n",
    "print(\"[INFO] grid search accuracy: {:.2f}%\".format(acc * 100))\n",
    "print(\"[INFO] randomized search best parameters: {}\".format(\n",
    "    grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = \"nearest\",\n",
    "    zoom_range = 0.3,\n",
    "    width_shift_range = 0.3,\n",
    "    height_shift_range = 0.3,\n",
    "    rotation_range = 30)\n",
    "\n",
    "validate_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = \"nearest\",\n",
    "    zoom_range = 0.3,\n",
    "    width_shift_range = 0.3,\n",
    "    height_shift_range = 0.3,\n",
    "    rotation_range = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n epochs = n iterations over all the training data\n",
    "batch_size = 10\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "132/194 [===================>..........] - ETA: 10:44 - loss: 1.3047 - acc: 0.4371 - mean_squared_error: 0.1346 - categorical_crossentropy: 1.3047 - top_k_categorical_accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "model_final_augmentation = get_model()\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "val = validate_datagen.fit(x_validation)\n",
    "model_final_augmentation.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size), \n",
    "                                                           epochs=epochs, \n",
    "                                                           callbacks=[TensorBoard(log_dir=config.tmp_model_dir)])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1940/1940 [==============================] - 1173s 605ms/step - loss: 5.6430 - acc: 0.5840 - mean_squared_error: 0.1595 - categorical_crossentropy: 5.6430 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 2/15\n",
      "1940/1940 [==============================] - 1246s 642ms/step - loss: 4.6797 - acc: 0.6840 - mean_squared_error: 0.1241 - categorical_crossentropy: 4.6797 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 3/15\n",
      "1940/1940 [==============================] - 1241s 640ms/step - loss: 4.0543 - acc: 0.7232 - mean_squared_error: 0.1077 - categorical_crossentropy: 4.0543 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 4/15\n",
      "1940/1940 [==============================] - 1288s 664ms/step - loss: 2.7610 - acc: 0.8015 - mean_squared_error: 0.0770 - categorical_crossentropy: 2.7610 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 5/15\n",
      "1940/1940 [==============================] - 1221s 630ms/step - loss: 1.7671 - acc: 0.8562 - mean_squared_error: 0.0549 - categorical_crossentropy: 1.7671 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 6/15\n",
      "1940/1940 [==============================] - 1265s 652ms/step - loss: 1.2024 - acc: 0.9005 - mean_squared_error: 0.0384 - categorical_crossentropy: 1.2024 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 7/15\n",
      "1940/1940 [==============================] - 1136s 585ms/step - loss: 0.7777 - acc: 0.9361 - mean_squared_error: 0.0249 - categorical_crossentropy: 0.7777 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 8/15\n",
      "1940/1940 [==============================] - 1063s 548ms/step - loss: 0.6186 - acc: 0.9448 - mean_squared_error: 0.0207 - categorical_crossentropy: 0.6186 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 9/15\n",
      "1940/1940 [==============================] - 1070s 552ms/step - loss: 0.3795 - acc: 0.9619 - mean_squared_error: 0.0137 - categorical_crossentropy: 0.3795 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "1940/1940 [==============================] - 1075s 554ms/step - loss: 0.3026 - acc: 0.9716 - mean_squared_error: 0.0111 - categorical_crossentropy: 0.3026 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "1940/1940 [==============================] - 1055s 544ms/step - loss: 0.2431 - acc: 0.9778 - mean_squared_error: 0.0087 - categorical_crossentropy: 0.2431 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "1940/1940 [==============================] - 1090s 562ms/step - loss: 0.1933 - acc: 0.9809 - mean_squared_error: 0.0068 - categorical_crossentropy: 0.1933 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "1940/1940 [==============================] - 1072s 552ms/step - loss: 0.1519 - acc: 0.9830 - mean_squared_error: 0.0059 - categorical_crossentropy: 0.1519 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "1940/1940 [==============================] - 1086s 560ms/step - loss: 0.1482 - acc: 0.9866 - mean_squared_error: 0.0052 - categorical_crossentropy: 0.1482 - top_k_categorical_accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "1940/1940 [==============================] - 1073s 553ms/step - loss: 0.1786 - acc: 0.9820 - mean_squared_error: 0.0068 - categorical_crossentropy: 0.1786 - top_k_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b97a752d4372>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           validation_split=1/6, callbacks=[TensorBoard(log_dir=config.tmp_model_dir)])\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'models/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model_final = get_model()\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "model_final.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "          validation_split=1/6, callbacks=[TensorBoard(log_dir=config.tmp_model_dir)])\n",
    "\n",
    "model.save(config.dataset_dir + 'models/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model_final_augmentation.to_json()\n",
    "with open(config.dataset_dir + 'models/' + \"cnntransfer_augm.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_final_augmentation.save_weights(config.dataset_dir + 'models/' + \"cnntransferweights_augmen.h5\", \"w\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## running tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 54.67%\n",
      "54.67% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import sklearn.metrics.confusion_matrix\n",
    "\n",
    "def evaluate(model):\n",
    "    cvscores = []\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "\n",
    "evaluate(model_final_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                          title='Confusion matrix, without normalization')\n",
    "\n",
    "    # Plot normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                          title='Normalized confusion matrix')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  1  1 24  5]\n",
      " [ 0 41  2  1 16]\n",
      " [ 0 11 34  1 14]\n",
      " [ 0  0  0 55  5]\n",
      " [ 0  5  0  4 51]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y_pred_class = model_final.predict(x_test)\n",
    "# con = tf.confusion_matrix(labels=y_test, predictions=y_pred_class )\n",
    "# print(con)\n",
    "\n",
    "y_test_non_category = [ np.argmax(t) for t in y_test ]\n",
    "y_predict_non_category = [ np.argmax(t) for t in y_pred_class ]\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test_non_category, y_predict_non_category)\n",
    "print(conf_mat)\n",
    "# def confusion_matrix(model, x_test)\n",
    "#     y_pred_class = model_final.predict(X_test)\n",
    "#     con = tf.confusion_matrix(labels=y_train, predictions=y_pred_class )\n",
    "#     print(cont)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.07322677e-25 6.23139972e-23 5.47258744e-25 1.00000000e+00\n",
      "  2.43150552e-17]\n",
      " [1.08412965e-20 1.59648637e-20 1.00000000e+00 1.78932823e-23\n",
      "  3.43413177e-16]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00]\n",
      " ...\n",
      " [6.13331655e-23 1.03271442e-18 3.36715216e-19 1.00000000e+00\n",
      "  1.62746783e-13]\n",
      " [4.88326718e-13 6.10503293e-13 1.00000000e+00 1.92685326e-10\n",
      "  1.71265224e-09]\n",
      " [3.08337860e-07 9.26659167e-01 4.66392899e-04 8.69648939e-04\n",
      "  7.20044672e-02]]\n",
      "[3 2 4 4 1 1 4 3 2 4 2 3 4 3 4 1 4 3 2 4 3 2 1 1 4 4 3 0 3 4 4 3 3 4 4 3 4\n",
      " 4 1 3 4 2 3 4 4 0 1 4 2 0 0 1 3 0 3 4 0 3 1 1 3 3 1 2 1 3 4 4 4 4 3 1 0 4\n",
      " 3 2 3 4 1 4 2 4 2 2 0 1 3 0 3 3 4 4 4 4 4 4 3 3 1 4 1 1 3 3 0 3 2 0 3 4 4\n",
      " 3 0 4 4 2 0 4 0 2 2 3 3 0 4 4 2 1 1 3 4 3 4 4 2 3 1 4 4 2 4 3 2 4 4 1 0 4\n",
      " 0 4 1 1 2 4 3 4 3 3 4 4 1 1 2 4 3 1 1 3 1 3 0 1 4 1 3 4 3 0 3 4 4 4 1 1 3\n",
      " 3 3 3 4 0 3 4 3 1 3 2 2 1 4 4 0 3 4 1 4 1 1 2 3 0 1 3 4 1 2 1 1 3 4 1 0 3\n",
      " 1 3 3 4 4 1 1 0 4 4 3 1 3 3 1 2 4 1 3 3 2 1 4 1 3 2 4 3 3 1 3 4 3 2 2 4 3\n",
      " 0 0 3 3 2 3 3 1 2 1 0 2 1 3 3 4 3 3 4 3 4 4 4 2 1 0 4 3 2 1 3 3 4 4 4 4 0\n",
      " 4 3 2 1]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 5\n",
    "\n",
    "# from lable to categorial\n",
    "y_categorical = y_pred_class\n",
    "# from categorial to lable indexing\n",
    "y_pred = y_categorial.argmax(1)\n",
    "print(y_pred)\n",
    "# plot_confusion_matrix(conf_mat, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c25d2c510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "fig, ax = plot_confusion_matrix(conf_mat=conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pcanet = PCANet(\n",
    "        image_shape= (256),\n",
    "        filter_shape_l1=2, step_shape_l1=1, n_l1_output=4,\n",
    "        filter_shape_l2=2, step_shape_l2=1, n_l2_output=4,\n",
    "        block_shape=2\n",
    "    )\n",
    "pcanet.validate_structure()\n",
    "\n",
    "pcanet.fit(x_train)\n",
    "X_train = pcanet.transform(x_train)\n",
    "X_test = pcanet.transform(x_test)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=1234, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy: \" + str(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
