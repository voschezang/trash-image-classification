{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sklearn, pandas, numpy as np, random\n",
    "from sklearn import svm\n",
    "import skimage, skimage.io, skimage.filters\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cwd back to default\n",
    "os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN libs\n",
    "import keras\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, Conv3D, MaxPool2D, Dropout, Flatten\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom scripts\n",
    "import config # params, constants\n",
    "import data, models # functions that mutate outr data\n",
    "# from utils import utils, plot # custom functions, in local environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data # src/data.py\n",
    "dataset = data.init_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the amount of classes that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the n classes with the most occuring instances\n",
    "amt = 3\n",
    "classes = data.top_classes(dataset.labels, amt)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = []\n",
    "n_per_class = []\n",
    "tail = '.jpg'\n",
    "for cls in classes:\n",
    "    names = data.items_with_label(dataset.labels, cls)\n",
    "    train_names = [f for f in names if (f + tail) in dataset.train]\n",
    "    name_list.append(train_names)\n",
    "    n_per_class.append(len(train_names))\n",
    "    \n",
    "n = min(n_per_class)\n",
    "# (optional) reduce n to check whether the model can rember its input\n",
    "reduced_n = 50\n",
    "if n > reduced_n:    n = reduced_n\n",
    "x = []\n",
    "for ls in name_list:\n",
    "    for name in ls[:n]:\n",
    "        x.append(name)\n",
    "random.shuffle(x)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO rmv faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & convert images\n",
    "All input images should have the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO use crop\n",
    "# TODO first \n",
    "x_train, y_train, n = data.extract_all(dataset, x)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_info(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.multiple(x_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the labels\n",
    "\n",
    "Encode the labels to one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO y_test\n",
    "y_test = y_train\n",
    "y_train, y_test = data.labels_to_vectors(dataset, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Sequential model (keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = x_train.shape[0] # = length of the list of images (matrices)\n",
    "input_shape = x_train.shape[1:] # = shape of an individual image (matrix)\n",
    "output_length = (y_train[0]).shape[0] # = length of an individual label\n",
    "print(n_samples, input_shape)\n",
    "print('output length', output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_conv(input_shape, output_length, dropout=0.10):\n",
    "    # Convolutional layers\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(4, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2))) # strides=(2,2) - watch dims!?!\n",
    "    model.add(Conv2D(32, (9, 9), activation='relu'))\n",
    "    # reduce the number of dimensions\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(8, (6, 6), activation='relu'))\n",
    "    model.add(Dropout(dropout))  \n",
    "    # Dense layers\n",
    "    model.add(Flatten())  \n",
    "    # model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(output_length,activation='softmax'))\n",
    "    return model, model.summary\n",
    "\n",
    "dropout = 0.10\n",
    "model, summary = sequential_conv(input_shape, output_length, dropout)\n",
    "summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, summary = models.sequential_conv(input_shape, output_length)\n",
    "# summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "- Categorical cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "# Adam, SGD\n",
    "# sgd = Keras.optimizers.SGD(lr=0.01, clipnorm=1.)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "# top_k_categorical_accuracy(y_true, y_pred, k=5)\n",
    "# https://keras.io/metrics/\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy',\n",
    "    'mean_squared_error','categorical_crossentropy','top_k_categorical_accuracy'])\n",
    "# model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "# n epochs = n iterations over all the training data\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.tmp_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=1/6)\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "          validation_split=1/6, callbacks=[TensorBoard(log_dir=config.tmp_model_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(x_train[:10])\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i = result[0].argmax()\n",
    "result[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
