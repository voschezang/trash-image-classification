{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "import os\n",
    "import os, sklearn, pandas, numpy as np, random\n",
    "from sklearn import svm\n",
    "import skimage, skimage.io, skimage.filters\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.utils import shuffle\n",
    "import imp\n",
    "\n",
    "# from pcanet import PCANet\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mark/src/dog-breed-identification/src'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set cwd back to default\n",
    "os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset :: namedtuple(\n",
      "    ['train' = ['img_name']\n",
      "    , 'test' = ['img_name']\n",
      "    , 'validation' = ['img_name']\n",
      "    , 'labels' = pandas.df('img_name','label')\n",
      "    , 'dict_index_to_label' = dict to convert label_index -> label_name\n",
      "    , 'dict_label_to_index'= dict to convert label_name -> label_index\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# custom scripts\n",
    "import config # params, constants\n",
    "import data, models # functions that mutate outr data\n",
    "# from utils import utils, plot # custom functions, in local environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import data # src/data.py\n",
    "dataset = data.init_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the amount of classes that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paper', 'glass', 'plastic']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick the n classes with the most occuring instances\n",
    "amt = 3\n",
    "classes = data.top_classes(dataset.labels, amt)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "maxx = 10\n",
    "max_train = 10\n",
    "x_train, n = data.extract_topx_classes(dataset, classes, 'train', maxx, max_train)\n",
    "x_test, _ = data.extract_topx_classes(dataset, classes, 'test', maxx, max_train)\n",
    "x_validation, _ = data.extract_topx_classes(dataset, classes, 'validation', maxx, max_train)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "for a in [x_train,x_test,x_validation]:\n",
    "    print(len(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and convert images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract all data: 30\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, n = data.extract_all(dataset, x_train, dirname='train/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract all data: 30\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test, n = data.extract_all(dataset, x_test, dirname='test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract all data: 30\n"
     ]
    }
   ],
   "source": [
    "x_validation, y_validation, n  = data.extract_all(dataset, x_validation, dirname='validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels and determine input and output shape for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "y_train, y_test, y_validation = data.labels_to_vectors(dataset, y_train, y_test, y_validation)\n",
    "input_shape = x_train.shape[1:] # = shape of an individual image (matrix)\n",
    "output_length = (y_train[0]).shape[0] # = length of an individual label\n",
    "print(output_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate VG16 network and add extra layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model \n",
    "\n",
    "def get_model(learn_rate=0.01, dropout=0.10, epochs=2, batch_size=5):\n",
    "    # build the VGG16 network\n",
    "    # global input_shape\n",
    "    model = applications.VGG16(weights='imagenet', include_top=False, input_shape = input_shape )\n",
    "    print('Model loaded, n layers:',  len(model.layers))\n",
    "\n",
    "\n",
    "    for layer in model.layers[0:15]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #Adding custom Layers \n",
    "    x = model.output\n",
    "    x = Flatten()(x)\n",
    "    x = (Dense(128, activation='relu'))(x) #128\n",
    "    x = (Dropout(dropout))(x)\n",
    "    x = (Dense(16, activation='relu'))(x)\n",
    "    # softmax output to get probability distribution\n",
    "    predictions = Dense(output_length, activation=\"softmax\")(x)\n",
    "\n",
    "\n",
    "    # creating the final model \n",
    "    model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "    # Adam, SGD\n",
    "    # sgd = Keras.optimizers.SGD(lr=0.01, clipnorm=1.)\n",
    "    optimizer = optimizers.Adam(lr=learn_rate)\n",
    "\n",
    "    # compile the model \n",
    "    model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizer, metrics=['accuracy',\n",
    "        'mean_squared_error','categorical_crossentropy','top_k_categorical_accuracy'])\n",
    "    \n",
    "    return model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import time\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# batches = [5, 10, 20]\n",
    "# learn_rate = [0.0001, 0.001, 0.01]\n",
    "# dropout = [0.05, 0.1, 0.25] # most used values\n",
    "param_grid = {'learn_rate':[0.01,0.001,0.001],'dropout':[0.05,0.1,0.25]}\n",
    "param_grid = {'learn_rate':[0.001,0.001]} # ,'dropout':[0.05,0.1,0.25]}\n",
    "\n",
    "# n = len(param_grid.values()) + 1\n",
    "n =1\n",
    "\n",
    "# tune the hyperparameters via a randomized search\n",
    "model = KerasClassifier(build_fn=get_model) # verbose=0\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=n, n_jobs=1)\n",
    "# watch memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20/20 [==============================] - 53s 3s/step - loss: 6.0654 - acc: 0.2000 - mean_squared_error: 0.2342 - categorical_crossentropy: 6.0654 - top_k_categorical_accuracy: 1.0000\n",
      "10/10 [==============================] - 19s 2s/step\n",
      "Model loaded.\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 55s 3s/step - loss: 9.7924 - acc: 0.2500 - mean_squared_error: 0.2424 - categorical_crossentropy: 9.7924 - top_k_categorical_accuracy: 0.7500\n",
      "10/10 [==============================] - 18s 2s/step\n",
      "Model loaded.\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 51s 3s/step - loss: 14.4697 - acc: 0.0000e+00 - mean_squared_error: 0.3207 - categorical_crossentropy: 14.4697 - top_k_categorical_accuracy: 0.7500\n",
      "10/10 [==============================] - 20s 2s/step\n",
      "Model loaded.\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 140s 5s/step - loss: 8.8702 - acc: 0.1667 - mean_squared_error: 0.2454 - categorical_crossentropy: 8.8702 - top_k_categorical_accuracy: 0.8333\n",
      "[INFO] randomized search took 365.14 seconds\n",
      "30/30 [==============================] - 133s 4s/step\n",
      "[INFO] grid search accuracy: 36.67%\n",
      "[INFO] randomized search best parameters: {'learn_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "# evaluate the best randomized searched model on the testing\n",
    "# data\n",
    "print(\"\\n[INFO] randomized search took {:.2f} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = grid.score(x_validation, y_validation)\n",
    "print(\"\\n[INFO] grid search accuracy: {:.2f}%\".format(acc * 100))\n",
    "print(\"[INFO] randomized search best parameters: {}\".format(\n",
    "    grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "(to increase the 'quality' of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = \"nearest\",\n",
    "    zoom_range = 0.3,\n",
    "    width_shift_range = 0.3,\n",
    "    height_shift_range=0.3,\n",
    "    rotation_range=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n epochs = n iterations over all the training data\n",
    "epochs = 1 # 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datagen.fit(x_train)\n",
    "\n",
    "# model_final.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "#                     steps_per_epoch=len(x_train) / batch_size, epochs=epochs, callbacks=[TensorBoard(log_dir=config.tmp_model_dir)])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.callbacks import TensorBoard\n",
    "# model_final.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "#           validation_split=1/6, callbacks=[TensorBoard(log_dir=config.tmp_model_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_final = get_model()\n",
    "# model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvscores = []\n",
    "# scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "# print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "# cvscores.append(scores[1] * 100)\n",
    "# print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pcanet import PCANet\n",
    "\n",
    "# pcanet = PCANet(\n",
    "#         image_shape= (512,348),\n",
    "#         filter_shape_l1=2, step_shape_l1=1, n_l1_output=4,\n",
    "#         filter_shape_l2=2, step_shape_l2=1, n_l2_output=4,\n",
    "#         block_shape=2\n",
    "#     )\n",
    "# pcanet.validate_structure()\n",
    "\n",
    "# pcanet.fit(x_train)\n",
    "# X_train = pcanet.transform(x_train)\n",
    "# X_test = pcanet.transform(x_test)\n",
    "\n",
    "# model = RandomForestClassifier(n_estimators=100, random_state=1234, n_jobs=-1)\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"accuracy: \" + str(accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
